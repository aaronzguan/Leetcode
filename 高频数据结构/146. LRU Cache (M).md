##146. LRU Cache (M)

Design and implement a data structure for [Least Recently Used (LRU) cache](https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU). It should support the following operations: `get` and `put`.

`get(key)` - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1.
`put(key, value)` - Set or insert the value if the key is not already present. When the cache reached its capacity, it should invalidate the least recently used item before inserting a new item.

```
LRUCache cache = new LRUCache( 2 /* capacity */ );

cache.put(1, 1);
cache.put(2, 2);
cache.get(1);       // returns 1
cache.put(3, 3);    // evicts key 2
cache.get(2);       // returns -1 (not found)
cache.put(4, 4);    // evicts key 1
cache.get(1);       // returns -1 (not found)
cache.get(3);       // returns 3
cache.get(4);       // returns 4
```

要求用O(1)的时间复杂度？ 

```python
class LinkedNode:
    def __init__(self, key=None, value=None, next=None):
        self.key = key
        self.value = value
        self.next = next

class LRUCache(object):

    def __init__(self, capacity):
        """
        :type capacity: int
        """
        self.capacity = capacity
        self.dummy = LinkedNode()
        self.tail = self.dummy
        self.key_to_prev = {}
        
    def get(self, key):
        """
        :type key: int
        :rtype: int
        """
        if key not in self.key_to_prev:
            return -1
        prev = self.key_to_prev[key]
        current = prev.next
        # 将当前节点放入最后，并且prev接入下一节点
        self.move_to_tail(prev)
        return current.value

    def put(self, key, value):
        """
        :type key: int
        :type value: int
        :rtype: None
        """
        if key in self.key_to_prev:
            # 若key存在，则将对应的节点移到最后
            self.move_to_tail(self.key_to_prev[key])
            # 并将该节点对应的值更改
            self.key_to_prev[key].next.value = value
            return
       	# 若不存在则将新节点加入链表最尾
        self.push_back(LinkedNode(key, value))
        # 若当前的长度超过capacity, 则移除最前端元素
        if len(self.key_to_prev) > self.capacity:
            self.pop_front()
            
	def move_to_tail(self, prev):
        """
        Change prev->node->next...->tail to prev->next...->tail->node
        """
        cur = prev.next
        # 若当前已经是最尾端，则无需移动
       	if cur == self.tail:
            return
        prev.next = cur.next
        self.key_to_prev[cur.next.key] = prev
        cur.next = None
        # 将cur移到链表最尾
        self.push_back(cur)
    
    def push_back(self, node):
        self.key_to_prev[node.key] = self.tail
        self.tail.next = node
        self.tail = node
    
    def pop_front(self):
        head = self.dummy.next
        self.dummy.next = head.next
        self.key_to_prev[head.next.key] = self.dummy
        del self.key_to_prev[head.key]
        
        
# Your LRUCache object will be instantiated and called as such:
# obj = LRUCache(capacity)
# param_1 = obj.get(key)
# obj.put(key,value)
```

